{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c02384",
   "metadata": {},
   "source": [
    "### Basic ReAct Agent using Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee87105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c304a",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae5a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt\n",
    "# sys = \"\"\"\n",
    "# You are an expert academic professor specializing in explaining complex concepts in a simple and engaging manner. You don't just answer directly but you break whole solution into multple parts and then create questions for each part to help the user understand the concept step by step. You also provide examples and analogies to make the explanation relatable. Your goal is to ensure that the user not only understands the concept but can also apply it in real-world scenarios.\n",
    "# Your task includes:\n",
    "# 1. Breaking down complex concepts into manageable small parts.\n",
    "# 2. Creating questions for each part to guide the user through the learning process.\n",
    "# 3. If user gets answer wrong for small part, you will provide hints and ask them to try again.\n",
    "# 4. If user gets answer wrong twice, you will provide the correct answer and explain why it is correct.\n",
    "# 5. If user gets answer right, you appreciate them and ask next question.\n",
    "# 6. You follow this cycle until whole explanation is complete.\n",
    "# \"\"\"\n",
    "\n",
    "sys = \"\"\"\n",
    "Your name is AcadGenie, an expert academic assistant specializing in guiding learners through complex concepts by breaking them down into manageable steps. Your role is not only to provide answers, but to foster deep understanding through an interactive dialogue. \n",
    "You use multiple diagnostic steps to ensure clarity and comprehension.\n",
    "\n",
    "You follow a guided practice flow, structured as follows:\n",
    "1. When a user asks a question, you first evaluate whether the question should be broken down into multiple smaller diagnostic steps.\n",
    "   - If it is simple, you provide a direct but clear answer with brief context or example.\n",
    "   - If it is complex, you break it into smaller parts and guide the user through each.\n",
    "\n",
    "2. For complex questions:\n",
    "   - Decompose the concept into smaller steps.\n",
    "   - Create one guiding question per step.\n",
    "   - Ask each question one by one.\n",
    "\n",
    "3. For each guiding question:\n",
    "   - If the user answers correctly, affirm and proceed to the next step.\n",
    "   - If the user answers incorrectly:\n",
    "     a. Give a hint on the first wrong attempt.\n",
    "     b. Give the correct answer and an explanation on the second wrong attempt.\n",
    "   - Reinforce understanding with examples or analogies.\n",
    "\n",
    "4. After the full concept has been explored:\n",
    "   - Ask if the user wants to explore another question.\n",
    "   - If they do, repeat the above cycle.\n",
    "\n",
    "Your tone is warm, supportive, and highly pedagogical. Always aim to ensure the user gains true conceptual clarity and can apply their knowledge in real-world or academic contexts.\n",
    "\n",
    "## Output Format:\n",
    "Each question you create should always be a multiple-choice question but it could be true/false MCQ, fill in the blank MCQ, etc.\n",
    "Each question should be in following format:\n",
    "```json\n",
    "{\n",
    "    \"question\": \"Your question here?\",\n",
    "    \"options\": [\n",
    "        {\"option\": \"A\", \"text\": \"Option A text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"B\", \"text\": \"Option B text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"C\", \"text\": \"Option C text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"D\", \"text\": \"Option D text\", \"DR\": \"misconception or common mistake which may lead to this answer\"}\n",
    "    ],\n",
    "    \"correct_option\": \"A\"  # or B, C, D depending on the correct answer,\n",
    "    \"explanation\": \"A brief explanation of why the correct answer is correct and why the others are not.\",\n",
    "    \"comment\": \"A brief comment to encourage the user or provide additional context. For example, 'Great job! This concept is crucial for understanding X.', 'This is a common misconception. Let's clarify it.', etc.\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869e7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "\n",
    "class Option(BaseModel):\n",
    "    option: str\n",
    "    text: str\n",
    "    DR: str\n",
    "\n",
    "class step_question_response(BaseModel):\n",
    "    question: str\n",
    "    options: List[Option]\n",
    "    correct_option: str\n",
    "    explanation: str\n",
    "    comment: str\n",
    "    hint: str\n",
    "    \n",
    "    class Config:\n",
    "        validate_by_name = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bd4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "# from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# checkpointer = InMemorySaver()\n",
    "\n",
    "# model = init_chat_model(\n",
    "#     \"openai:gpt-4o\",\n",
    "#     temperature=0.3\n",
    "# )\n",
    "\n",
    "# agent = create_react_agent(\n",
    "#     model=model,\n",
    "#     prompt=sys,\n",
    "#     checkpointer=checkpointer,\n",
    "#     response_model=step_question_response,\n",
    "#     # max_iterations=10,\n",
    "#     # max_steps=5,\n",
    "# )\n",
    "\n",
    "# config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# sf_response = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "#     config  \n",
    "# )\n",
    "# ny_response = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"what about new york?\"}]},\n",
    "#     config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ffd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# Create a conversation history class\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def add_message(self, role: str, content: str):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def get_messages(self):\n",
    "        return self.messages\n",
    "\n",
    "# Define the dynamic prompt for the agent\n",
    "def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:  \n",
    "    user_name = config[\"configurable\"].get(\"user_name\")\n",
    "    system_msg = f\"{sys}. Address the user as {user_name}.\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "\n",
    "# Initialize conversation history\n",
    "# conversation = ConversationHistory()\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4o\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    tools=[],\n",
    "    checkpointer=checkpointer,\n",
    "    response_format={\n",
    "        \"name\": \"step_question_response\",\n",
    "        \"description\": \"Response format for educational questions\",\n",
    "        \"schema\": step_question_response.model_json_schema()\n",
    "    }\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"user_name\": \"Shishir Dwivedi\", \"thread_id\": \"1\"}}\n",
    "\n",
    "# def get_response(user_input: str) -> dict:\n",
    "#     # Add user message to history\n",
    "#     conversation.add_message(\"user\", user_input)\n",
    "    \n",
    "#     # Get response using full conversation history\n",
    "#     response = agent.invoke(\n",
    "#         {\"messages\": conversation.get_messages()},\n",
    "#         config\n",
    "#     )\n",
    "#     print(\"Agent: \", response)\n",
    "#     # Add assistant's response to history\n",
    "#     conversation.add_message(\"assistant\", response.dict())\n",
    "    \n",
    "#     return response\n",
    "\n",
    "# responses = []\n",
    "\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         break\n",
    "#     response = get_response(user_input)\n",
    "#     print(\"Assistant:\", response)\n",
    "\n",
    "def get_response(user_input: str) -> dict:\n",
    "    # Add user message to history\n",
    "    # conversation.add_message(\"user\", user_input)\n",
    "    \n",
    "    # Get response using full conversation history\n",
    "    print(\"\\n--- Conversation History ---\")\n",
    "    # for msg in conversation.get_messages():\n",
    "    #     print(f\"{msg['role'].capitalize()}: {msg['content']}\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"\\n--- Asking Agent ---\")\n",
    "    print(\"User:\", user_input)\n",
    "    # Invoke the agent with the conversation history\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # Extract messages from response\n",
    "    messages = response.get('messages', [])\n",
    "    human_message = next((msg for msg in messages if isinstance(msg, HumanMessage)), None)\n",
    "    ai_message = next((msg for msg in messages if isinstance(msg, AIMessage)), None)\n",
    "    \n",
    "    # Extract structured response\n",
    "    structured_response = response.get('structured_response', {})\n",
    "    \n",
    "    # if ai_message:\n",
    "        # conversation.add_message(\"assistant\", structured_response)\n",
    "    \n",
    "    if human_message:\n",
    "        print(\"\\nHuman:\", human_message.content)\n",
    "    if ai_message:\n",
    "        print(\"Assistant:\", ai_message.content)\n",
    "    \n",
    "    if structured_response:\n",
    "        print(\"\\n--- Structured Response ---\")\n",
    "        print(\"Question:\", structured_response['question'])\n",
    "        print(\"\\nOptions:\")\n",
    "        for option in structured_response['options']:\n",
    "            print(f\"{option['option']}: {option['text']}\")\n",
    "        print(\"\\nCorrect Answer:\", structured_response['correct_option'])\n",
    "        print(\"\\nExplanation:\", structured_response['explanation'])\n",
    "        print(\"\\nComment:\", structured_response['comment'])\n",
    "        print(\"-------------------------\")\n",
    "    \n",
    "    return {\n",
    "        'human_message': human_message.content if human_message else None,\n",
    "        'ai_message': ai_message.content if ai_message else None,\n",
    "        'structured_response': structured_response\n",
    "    }\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    # ai_response = response['ai_message']\n",
    "    # structured_data = response['structured_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# from react_agent_langgraph import get_response, conversation  # Import from your notebook file\n",
    "\n",
    "# def init_session_state():\n",
    "#     if \"messages\" not in st.session_state:\n",
    "#         st.session_state.messages = []\n",
    "\n",
    "# def display_message(role, content, structured_data=None):\n",
    "#     with st.chat_message(role):\n",
    "#         st.write(content)\n",
    "#         if structured_data:\n",
    "#             with st.expander(\"Question Details\"):\n",
    "#                 st.write(\"**Question:**\", structured_data['question'])\n",
    "#                 st.write(\"**Options:**\")\n",
    "#                 for option in structured_data['options']:\n",
    "#                     st.write(f\"- {option['option']}: {option['text']}\")\n",
    "                \n",
    "#                 # Create columns for answer-related information\n",
    "#                 col1, col2 = st.columns(2)\n",
    "#                 with col1:\n",
    "#                     st.write(\"**Correct Answer:**\", structured_data['correct_option'])\n",
    "#                 with col2:\n",
    "#                     if st.button(\"Show Explanation\", key=f\"explain_{len(st.session_state.messages)}\"):\n",
    "#                         st.write(\"**Explanation:**\", structured_data['explanation'])\n",
    "#                         st.write(\"**Comment:**\", structured_data['comment'])\n",
    "\n",
    "# def main():\n",
    "#     st.title(\"Educational AI Assistant\")\n",
    "#     st.write(\"\"\"\n",
    "#     Welcome to your interactive learning session! \n",
    "#     Ask any question, and I'll guide you through the concept step by step.\n",
    "#     \"\"\")\n",
    "    \n",
    "#     init_session_state()\n",
    "    \n",
    "#     # Display chat history\n",
    "#     for message in st.session_state.messages:\n",
    "#         display_message(\n",
    "#             message[\"role\"],\n",
    "#             message[\"content\"],\n",
    "#             message.get(\"structured_data\")\n",
    "#         )\n",
    "    \n",
    "#     # Chat input\n",
    "#     if prompt := st.chat_input(\"What would you like to learn about?\"):\n",
    "#         # Display user message\n",
    "#         display_message(\"user\", prompt)\n",
    "#         st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "#         # Get AI response\n",
    "#         response = get_response(prompt)\n",
    "        \n",
    "#         # Display AI response\n",
    "#         display_message(\n",
    "#             \"assistant\",\n",
    "#             response['ai_message'] if response['ai_message'] else \"\",\n",
    "#             response['structured_response']\n",
    "#         )\n",
    "        \n",
    "#         # Save to session state\n",
    "#         st.session_state.messages.append({\n",
    "#             \"role\": \"assistant\",\n",
    "#             \"content\": response['ai_message'] if response['ai_message'] else \"\",\n",
    "#             \"structured_data\": response['structured_response']\n",
    "#         })\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f0e526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c920a3747b3d4e87a30db31ba7414be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', layout=Layout(width='80%'), placehoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class NotebookChatUI:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.output = widgets.Output()\n",
    "        self.text_input = widgets.Text(\n",
    "            placeholder='Ask a question...',\n",
    "            description='You:',\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        self.send_button = widgets.Button(description='Send')\n",
    "        self.send_button.on_click(self.on_send)\n",
    "        \n",
    "        # Layout\n",
    "        self.container = widgets.VBox([\n",
    "            self.output,\n",
    "            widgets.HBox([self.text_input, self.send_button])\n",
    "        ])\n",
    "    \n",
    "    def display_message(self, role, content, structured_data=None):\n",
    "        with self.output:\n",
    "            print(f\"{role.title()}: {content}\")\n",
    "            if structured_data:\n",
    "                print(\"\\nQuestion Details:\")\n",
    "                print(f\"Q: {structured_data['question']}\")\n",
    "                print(\"\\nOptions:\")\n",
    "                for option in structured_data['options']:\n",
    "                    print(f\"- {option['option']}: {option['text']}\")\n",
    "    \n",
    "    def on_send(self, button):\n",
    "        user_input = self.text_input.value\n",
    "        self.text_input.value = ''\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            return\n",
    "        \n",
    "        # Display user message\n",
    "        self.display_message('user', user_input)\n",
    "        \n",
    "        # Get and display AI response\n",
    "        response = get_response(user_input)\n",
    "        self.display_message(\n",
    "            'assistant', \n",
    "            response['ai_message'] if response['ai_message'] else \"\",\n",
    "            response['structured_response']\n",
    "        )\n",
    "    \n",
    "    def start(self):\n",
    "        display(self.container)\n",
    "\n",
    "# Create and start the chat UI\n",
    "chat_ui = NotebookChatUI()\n",
    "chat_ui.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2b5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112d252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d5f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b56a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f91e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859debc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a73c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63f985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Guided Practice)",
   "language": "python",
   "name": "guided-practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
