{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8d608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Major Dependencies\n",
    "# !pip install langgraph-supervisor langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b015273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cd067",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_system = \"\"\"\n",
    "You are AcadGenie, an expert academic assistant specializing in guiding learners through complex concepts by breaking them down into manageable steps. Your role is not only to provide answers but to foster deep understanding through interactive dialogue. You are responsible for managing the conversation with the user, deciding how to respond based on their input, and delegating the creation of diagnostic questions to the React Agent when necessary. You follow a guided practice flow as outlined below.\n",
    "\n",
    "Interaction Flow:\n",
    "- Evaluate User Input:\n",
    "    If the user's input is not a question, engage in normal conversation, providing helpful, supportive, and contextually appropriate responses.\n",
    "    If the user's input is a question, determine whether it is simple or complex:\n",
    "        --> Simple or small Questions(For example, definitions, terms etc.): Provide a direct but clear answer with brief context or an example.\n",
    "        --> Hard, long or Complex Questions: Proceed to break it down into smaller steps as described below.\n",
    "\n",
    "- Handling hard, long or  Complex Questions:\n",
    "    Decompose the concept into smaller, manageable steps to guide the user toward a complete solution.\n",
    "    For each step, request the React Agent to generate a diagnostic question by providing:\n",
    "        --> The topic (the subject or concept being addressed),\n",
    "        --> The problem (the specific challenge or sub-question within the step),\n",
    "        --> A comment (additional context or guidance for question creation).\n",
    "    Present each diagnostic question to the user one by one in a readable format (e.g., question followed by options A, B, C, D).\n",
    "\n",
    "- Managing User Responses to Diagnostic Questions:\n",
    "    Present the question and its multiple-choice options to the user.\n",
    "    Evaluate the user's answer:\n",
    "        -If correct:\n",
    "        --> Affirm their understanding (e.g., \"Great job!\" or use the comment from the React Agent's response).\n",
    "        --> Proceed to the next step or question.\n",
    "        - If incorrect:\n",
    "        --> On the first wrong attempt, provide a hint to guide the user.\n",
    "        --> On the second wrong attempt, provide the correct answer along with the explanation provided by the React Agent.\n",
    "    Reinforce understanding with examples or analogies where appropriate.\n",
    "\n",
    "- After Exploring the Full Concept:\n",
    "    Once all steps are completed and the concept is fully explored, ask the user: \"Would you like to explore another question?\"\n",
    "    If they respond affirmatively, repeat the cycle for the new question.\n",
    "\n",
    "Tone and Style:\n",
    "    Maintain a warm, supportive, and highly pedagogical tone throughout the interaction.\n",
    "    Ensure the user gains true conceptual clarity and can apply their knowledge in real-world or academic contexts.\n",
    "\n",
    "Notes:\n",
    "    You interact directly with the user and control the flow of the conversation.\n",
    "    For complex questions, you rely on the React Agent to generate diagnostic questions in a specific JSON format, which includes the question, options, correct option, explanation, and comment.\n",
    "    You are responsible for formatting the React Agent's JSON output into a user-friendly presentation and using the provided explanation and comment to give feedback based on the user's responses.\n",
    "\n",
    "## Output Format:\n",
    "Output you create must be structured as follows:\n",
    "```json\n",
    "{\n",
    "    \"conversation_message\": \"Your message regarding conversation here.\",\n",
    "    \"question_data\": {\n",
    "        \"question\": \"Your question here?\",\n",
    "        \"options\": [\n",
    "            {\"option\": \"A\", \"text\": \"Option A text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "            {\"option\": \"B\", \"text\": \"Option B text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "            {\"option\": \"C\", \"text\": \"Option C text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "            {\"option\": \"D\", \"text\": \"Option D text\", \"DR\": \"misconception or common mistake which may lead to this answer\"}\n",
    "        ],\n",
    "        \"correct_option\": \"A\",  // or B, C, D depending on the correct answer\n",
    "        \"explanation\": \"A brief explanation of why the correct answer is correct and why the others are not.\",\n",
    "        \"comment\": \"A brief comment to encourage the user or provide additional context. For example, 'Great job! This concept is crucial for understanding X.', 'This is a common misconception. Let's clarify it.', etc.\"\n",
    "    },\n",
    "}\n",
    "```\n",
    "Make sure all the keys in the JSON are present and correctly formatted.\n",
    "Do not give any other output other than question and related conversation message. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "react_system = \"\"\"\n",
    "You are the React Agent, a component of the AcadGenie system. Your sole responsibility is to generate diagnostic questions based on the input provided by the Supervisor Agent. These questions help learners understand complex concepts through interactive dialogue. You do not interact directly with the user; your output is used by the Supervisor Agent.\n",
    "\n",
    "Task:\n",
    "Generate a diagnostic question based on the topic, problem, and comment provided by the Supervisor Agent.\n",
    "Each question must be a multiple-choice question (which could be styled as true/false, fill-in-the-blank, etc.) and follow the specified JSON format below.\n",
    "Question Format:\n",
    "Each diagnostic question you create must be structured as follows:\n",
    "```json\n",
    "{\n",
    "    \"question\": \"Your question here?\",\n",
    "    \"options\": [\n",
    "        {\"option\": \"A\", \"text\": \"Option A text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"B\", \"text\": \"Option B text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"C\", \"text\": \"Option C text\", \"DR\": \"misconception or common mistake which may lead to this answer\"},\n",
    "        {\"option\": \"D\", \"text\": \"Option D text\", \"DR\": \"misconception or common mistake which may lead to this answer\"}\n",
    "    ],\n",
    "    \"correct_option\": \"A\",  // or B, C, D depending on the correct answer\n",
    "    \"explanation\": \"A brief explanation of why the correct answer is correct and why the others are not.\",\n",
    "    \"comment\": \"A brief comment to encourage the user or provide additional context. For example, 'Great job! This concept is crucial for understanding X.', 'This is a common misconception. Let's clarify it.', etc.\"\n",
    "}\n",
    "```\n",
    "Guidelines:\n",
    "Ensure the question is pedagogically sound and directly relates to the topic and problem provided.\n",
    "Include plausible distractors (DR) in the options, reflecting common misconceptions or mistakes learners might make.\n",
    "Provide a clear and concise explanation that justifies the correct answer and addresses why the other options are incorrect.\n",
    "Include an encouraging or contextual comment to enhance the learning experience.\n",
    "Interaction:\n",
    "You receive requests from the Supervisor Agent containing the topic, problem, and comment.\n",
    "In response, you generate a diagnostic question in the specified JSON format and return it to the Supervisor Agent.\n",
    "You do not interact with the user; your role is limited to question creation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1aa919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add human in the loop wrapper\n",
    "\n",
    "from typing import Callable\n",
    "from langchain_core.tools import BaseTool, tool as create_tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt \n",
    "from langgraph.prebuilt.interrupt import HumanInterruptConfig, HumanInterrupt\n",
    "\n",
    "def add_human_in_the_loop(\n",
    "    tool: Callable | BaseTool,\n",
    "    *,\n",
    "    interrupt_config: HumanInterruptConfig = None,\n",
    ") -> BaseTool:\n",
    "    \"\"\"Wrap a tool to support human-in-the-loop review.\"\"\" \n",
    "    if not isinstance(tool, BaseTool):\n",
    "        tool = create_tool(tool)\n",
    "\n",
    "    if interrupt_config is None:\n",
    "        interrupt_config = {\n",
    "            \"allow_accept\": True,\n",
    "            \"allow_edit\": True,\n",
    "            \"allow_respond\": True,\n",
    "        }\n",
    "\n",
    "    @create_tool(  \n",
    "        tool.name,\n",
    "        description=tool.description,\n",
    "        args_schema=tool.args_schema\n",
    "    )\n",
    "    def call_tool_with_interrupt(config: RunnableConfig, **tool_input):\n",
    "        request: HumanInterrupt = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool.name,\n",
    "                \"args\": tool_input\n",
    "            },\n",
    "            \"config\": interrupt_config,\n",
    "            \"description\": \"Please review the tool call\"\n",
    "        }\n",
    "        response = interrupt([request])[0]  \n",
    "        # approve the tool call\n",
    "        if response[\"type\"] == \"accept\":\n",
    "            tool_response = tool.invoke(tool_input, config)\n",
    "        # update tool call args\n",
    "        elif response[\"type\"] == \"edit\":\n",
    "            tool_input = response[\"args\"][\"args\"]\n",
    "            tool_response = tool.invoke(tool_input, config)\n",
    "        # respond to the LLM with user feedback\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            user_feedback = response[\"args\"]\n",
    "            tool_response = user_feedback\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported interrupt response type: {response['type']}\")\n",
    "\n",
    "        return tool_response\n",
    "\n",
    "    return call_tool_with_interrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\", )\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "# Print the completion returned by the LLM.\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56814110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "\n",
    "\n",
    "# class State(TypedDict):\n",
    "#     messages: Annotated[list, add_messages]\n",
    "#     remaining_steps: any\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    remaining_steps: any\n",
    "    memory: ConversationBufferWindowMemory\n",
    "    \n",
    "def initialize_state() -> State:\n",
    "    \"\"\"Initialize the state with memory.\"\"\"\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"remaining_steps\": None,\n",
    "        \"memory\": []  # Keep last 10 interactions\n",
    "    }\n",
    "state = initialize_state()  \n",
    "\n",
    "# @tool\n",
    "# def human_assistance(query: str) -> str:\n",
    "#     \"\"\"Request assistance from a human.\"\"\"\n",
    "#     human_response = interrupt({\"query\": query})\n",
    "#     return human_response[\"data\"]\n",
    "\n",
    "# def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:  \n",
    "#     user_name = config[\"configurable\"].get(\"user_name\")\n",
    "#     system_msg = f\"{supervisor_system}. Address the user as {user_name}.\"\n",
    "#     return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "\n",
    "def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:  \n",
    "    user_name = config[\"configurable\"].get(\"user_name\")\n",
    "    system_msg = f\"{supervisor_system}. Address the user as {user_name}.\"\n",
    "    \n",
    "    # Get messages from memory\n",
    "    memory_messages = state[\"memory\"] if \"memory\" in state else []\n",
    "    \n",
    "    # Combine system message, memory messages, and current messages\n",
    "    all_messages = [SystemMessage(content=system_msg)] + memory_messages + state[\"messages\"]\n",
    "    \n",
    "    return all_messages\n",
    "\n",
    "config = {\"configurable\": {\"user_name\": \"Shishir Dwivedi\", \"thread_id\": \"1\"}}\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# diagnostic question creation agent\n",
    "question_creation_agent = create_react_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    "    # tools=[add_human_in_the_loop],\n",
    "    tools=[],\n",
    "    name=\"question_creation_expert\",\n",
    "    prompt=react_system\n",
    ")\n",
    "\n",
    "#supervisor agent \n",
    "workflow = create_supervisor(\n",
    "    [question_creation_agent],\n",
    "    supervisor_name=\"AcadGenie\",\n",
    "    output_mode=\"full_history\",\n",
    "    add_handoff_back_messages=True,\n",
    "    state_schema=State,\n",
    "    model=model,\n",
    "    prompt=prompt\n",
    ")\n",
    "# Compile the workflow\n",
    "app = workflow.compile()\n",
    "\n",
    "# def get_response(usr_input: str) -> dict:\n",
    "    # \"\"\"Function to get the response from the supervisor agent.\"\"\"\n",
    "    # print(\"\\n---------- User message ----------\\n\")\n",
    "    # print(\"User:\", usr_input)\n",
    "    # print(\"\\n---------- Asking Agent ----------\\n\")\n",
    "    # response =  app.invoke({\n",
    "    #     \"messages\": [\n",
    "    #         {\n",
    "    #             \"role\": \"user\",\n",
    "    #             \"content\": usr_input\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }, config)\n",
    "\n",
    "    # # Extract messages from response\n",
    "    # messages = response.get('messages', [])\n",
    "    # print(\"\\n---------- Agent response ----------\\n\" )\n",
    "    # for msg in messages:\n",
    "    #     if isinstance(msg, HumanMessage):\n",
    "    #         print(\"Human:\", msg.content)\n",
    "    #     elif isinstance(msg, AIMessage):\n",
    "    #         print(\"Assistant:\", msg.content)\n",
    "    #     else:\n",
    "    #         print(\"Other message type:\", msg)\n",
    "    # human_message = next((msg for msg in messages if isinstance(msg, HumanMessage)), None)\n",
    "    # ai_message = next((msg for msg in messages if isinstance(msg, AIMessage)), None)\n",
    "    # structured_response = response.get('structured_response', {})\n",
    "\n",
    "    # if human_message:\n",
    "    #     print(\"\\nHuman:\", human_message.content)\n",
    "    # if ai_message:\n",
    "    #     print(\"Assistant:\", ai_message.content)\n",
    "    \n",
    "    # if structured_response:\n",
    "    #     print(\"\\n--- Structured Response ---\")\n",
    "    #     print(\"Question:\", structured_response['question'])\n",
    "    #     print(\"\\nOptions:\")\n",
    "    #     for option in structured_response['options']:\n",
    "    #         print(f\"{option['option']}: {option['text']}\")\n",
    "    #     print(\"\\nCorrect Answer:\", structured_response['correct_option'])\n",
    "    #     print(\"\\nExplanation:\", structured_response['explanation'])\n",
    "    #     print(\"\\nComment:\", structured_response['comment'])\n",
    "    #     print(\"-------------------------\")\n",
    "    \n",
    "    # return {\n",
    "    #     'human_message': human_message.content if human_message else None,\n",
    "    #     'ai_message': ai_message.content if ai_message else None,\n",
    "    #     'structured_response': structured_response\n",
    "    # }\n",
    "    \n",
    "# while working:\n",
    "#     try:\n",
    "#         usr_input = input(\"\\nEnter your question (or type 'exit' to quit): \")\n",
    "#         if usr_input.lower() == \"exit\":\n",
    "#             break\n",
    "#         response = get_response(usr_input)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "#         working = False\n",
    "\n",
    "def windowing_memory(state: State = state, max_length: int = 10) -> list[BaseMessage]:\n",
    "    selected_messages = trim_messages(\n",
    "        state['memory'],\n",
    "        token_counter=len,  # <-- len will simply count the number of messages rather than tokens\n",
    "        max_tokens=max_length,  # <-- allow up to 5 messages.\n",
    "        strategy=\"last\",\n",
    "        # Most chat models expect that chat history starts with either:\n",
    "        # (1) a HumanMessage or\n",
    "        # (2) a SystemMessage followed by a HumanMessage\n",
    "        # start_on=\"human\" makes sure we produce a valid chat history\n",
    "        start_on=\"human\",\n",
    "        # Usually, we want to keep the SystemMessage\n",
    "        # if it's present in the original history.\n",
    "        # The SystemMessage has special instructions for the model.\n",
    "        include_system=True,\n",
    "        allow_partial=False,)\n",
    "    \n",
    "    return selected_messages\n",
    "\n",
    "def get_response(usr_input: str, state: State = state) -> dict:\n",
    "    \"\"\"Function to get the response from the supervisor agent.\"\"\"\n",
    "    \n",
    "    print(\"\\n---------- User message ----------\\n\")\n",
    "    print(\"User:\", usr_input)\n",
    "    print(\"\\n---------- Asking Agent ----------\\n\")\n",
    "    \n",
    "    # Add the user message to memory\n",
    "    state[\"memory\"].append(HumanMessage(content=usr_input, name=\"user\"))\n",
    "    \n",
    "    response = app.invoke({\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": usr_input\n",
    "            }\n",
    "        ],\n",
    "        \"memory\": state[\"memory\"]\n",
    "    }, config)\n",
    "\n",
    "    # Extract messages from response\n",
    "    messages = response.get('messages', [])\n",
    "    print(\"\\n---------- Agent responses ----------\\n\")\n",
    "    \n",
    "    # Lists to store messages by agent\n",
    "    supervisor_messages = []\n",
    "    react_messages = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            # Check the message metadata or content to identify the agent\n",
    "            if hasattr(msg, 'name') and msg.name == \"question_creation_expert\":\n",
    "                react_messages.append(msg.content)\n",
    "                state[\"memory\"].append(AIMessage(content=msg.content, name=\"question_creation_expert\"))\n",
    "            else:\n",
    "                supervisor_messages.append(msg.content)\n",
    "                # Add to memory only supervisor messages to maintain conversation flow\n",
    "                state[\"memory\"].append(AIMessage(content=msg.content, name=\"AcadGenie\"))\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            print(\"Human:\", msg.content)\n",
    "        else:\n",
    "            print(\"Other message type:\", msg)\n",
    "\n",
    "    human_message = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), None)\n",
    "    structured_response = response.get('structured_response', {})\n",
    "    \n",
    "    # update state memory to make sure it doesn't have more than max_length messages\n",
    "    # state['memory'] = windowing_memory(max_length=30)\n",
    "    \n",
    "    return {\n",
    "        'human_message': human_message,\n",
    "        'supervisor_messages': supervisor_messages,\n",
    "        'react_messages': react_messages,\n",
    "        'structured_response': structured_response,\n",
    "        'memory': state[\"memory\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84b9169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7a51d53813d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6e068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2161876c",
   "metadata": {},
   "source": [
    "### Chat using IpyWidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41091def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .chat-output {\n",
       "                border: 1px solid #ccc;\n",
       "                border-radius: 5px;\n",
       "                padding: 10px;\n",
       "                margin: 5px;\n",
       "                background-color: #f9f9f9;\n",
       "            }\n",
       "            .user-message {\n",
       "                background-color: #e3f2fd;\n",
       "                padding: 8px;\n",
       "                border-radius: 10px;\n",
       "                margin: 5px;\n",
       "            }\n",
       "            .assistant-message {\n",
       "                background-color: #f5f5f5;\n",
       "                padding: 8px;\n",
       "                border-radius: 10px;\n",
       "                margin: 5px;\n",
       "            }\n",
       "            .structured-data {\n",
       "                background-color: #fff;\n",
       "                border-left: 3px solid #2196F3;\n",
       "                padding: 10px;\n",
       "                margin: 5px;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44835/1041886262.py:69: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  self.text_input.on_submit(self.on_send)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb11483de88140cf80067177d90bf743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border_bottom='1px solid #ccc', border_left='1px solid #ccc', border_right…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Output' object has no attribute 'scroll_to_bottom'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mNotebookChatUI.on_send\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMemory: \u001b[39m\u001b[33m\"\u001b[39m, state[\u001b[33m'\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Auto-scroll to bottom\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscroll_to_bottom\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Output' object has no attribute 'scroll_to_bottom'"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.display import HTML\n",
    "\n",
    "class NotebookChatUI:\n",
    "    def __init__(self):\n",
    "        # Add custom CSS for styling\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "            .chat-output {\n",
    "                border: 1px solid #ccc;\n",
    "                border-radius: 5px;\n",
    "                padding: 10px;\n",
    "                margin: 5px;\n",
    "                background-color: #f9f9f9;\n",
    "            }\n",
    "            .user-message {\n",
    "                background-color: #e3f2fd;\n",
    "                padding: 8px;\n",
    "                border-radius: 10px;\n",
    "                margin: 5px;\n",
    "            }\n",
    "            .assistant-message {\n",
    "                background-color: #f5f5f5;\n",
    "                padding: 8px;\n",
    "                border-radius: 10px;\n",
    "                margin: 5px;\n",
    "            }\n",
    "            .structured-data {\n",
    "                background-color: #fff;\n",
    "                border-left: 3px solid #2196F3;\n",
    "                padding: 10px;\n",
    "                margin: 5px;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "\n",
    "        self.messages = []\n",
    "        # Create scrollable output with fixed height\n",
    "        self.output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                height='400px',\n",
    "                overflow_y='auto',\n",
    "                border='1px solid #ccc',\n",
    "                border_radius='5px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Improved input field\n",
    "        self.text_input = widgets.Text(\n",
    "            placeholder='Type your question here...',\n",
    "            description='You:',\n",
    "            layout=widgets.Layout(\n",
    "                width='80%',\n",
    "                padding='5px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Styled send button\n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='primary',\n",
    "            icon='paper-plane',\n",
    "            layout=widgets.Layout(width='100px')\n",
    "        )\n",
    "        self.send_button.on_click(self.on_send)\n",
    "        \n",
    "        # Enter key binding\n",
    "        self.text_input.on_submit(self.on_send)\n",
    "\n",
    "        # Improved layout with spacing\n",
    "        input_box = widgets.HBox(\n",
    "            [self.text_input, self.send_button],\n",
    "            layout=widgets.Layout(padding='10px')\n",
    "        )\n",
    "        \n",
    "        self.container = widgets.VBox(\n",
    "            [self.output, input_box],\n",
    "            layout=widgets.Layout(\n",
    "                width='100%',\n",
    "                border='1px solid #ddd',\n",
    "                border_radius='10px',\n",
    "                padding='10px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def display_message(self, role, content, structured_data=None):\n",
    "        with self.output:\n",
    "            # Format messages with HTML styling\n",
    "            if role.lower() == 'user':\n",
    "                print(f\"<div class='user-message'><strong>You:</strong> {content}</div>\", flush=True)\n",
    "            else:\n",
    "                print(f\"<div class='assistant-message'><strong>Assistant:</strong> {content}</div>\", flush=True)\n",
    "\n",
    "            if structured_data:\n",
    "                print(\"<div class='structured-data'>\")\n",
    "                print(\"<strong>Question Details:</strong>\")\n",
    "                print(f\"<p>{structured_data['question']}</p>\")\n",
    "                print(\"<strong>Options:</strong>\")\n",
    "                for option in structured_data['options']:\n",
    "                    print(f\"<p>{option['option']}: {option['text']}</p>\")\n",
    "                print(\"</div>\", flush=True)\n",
    "\n",
    "    def on_send(self, *args):\n",
    "        user_input = self.text_input.value.strip()\n",
    "        self.text_input.value = ''\n",
    "        \n",
    "        if not user_input:\n",
    "            return\n",
    "            \n",
    "        if user_input.lower() == 'exit':\n",
    "            return\n",
    "        \n",
    "        # Display user message\n",
    "        self.display_message('user', user_input)\n",
    "        \n",
    "        # Get and display AI response\n",
    "        response = get_response(user_input)\n",
    "        self.display_message(\n",
    "            'assistant', \n",
    "            response['supervisor_messages'] if response['supervisor_messages'] else \"\",\n",
    "            response['structured_response']\n",
    "        )\n",
    "        print(\"Memory: \", state['memory'])\n",
    "        # Auto-scroll to bottom\n",
    "        self.output.scroll_to_bottom()\n",
    "    \n",
    "    def start(self):\n",
    "        display(self.container)\n",
    "\n",
    "# Create and start the chat UI\n",
    "chat_ui = NotebookChatUI()\n",
    "chat_ui.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12532ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "024a9fdb",
   "metadata": {},
   "source": [
    "### Chat using Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 14:03:48.543 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.698 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/shishir/Desktop/Guided-Practice/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-02 14:03:48.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.701 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-02 14:03:48.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-02 14:03:48.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "\n",
    "# def init_session_state():\n",
    "#     if \"messages\" not in st.session_state:\n",
    "#         st.session_state.messages = []\n",
    "\n",
    "# def display_message(role, content, structured_data=None):\n",
    "#     with st.chat_message(role):\n",
    "#         st.write(content)\n",
    "#         if structured_data:\n",
    "#             with st.expander(\"Question Details\"):\n",
    "#                 st.write(\"**Question:**\", structured_data['question'])\n",
    "#                 st.write(\"**Options:**\")\n",
    "#                 for option in structured_data['options']:\n",
    "#                     st.write(f\"- {option['option']}: {option['text']}\")\n",
    "                \n",
    "#                 col1, col2 = st.columns(2)\n",
    "#                 with col1:\n",
    "#                     st.write(\"**Correct Answer:**\", structured_data['correct_option'])\n",
    "#                 with col2:\n",
    "#                     if st.button(\"Show Explanation\", key=f\"explain_{len(st.session_state.messages)}\"):\n",
    "#                         st.write(\"**Explanation:**\", structured_data['explanation'])\n",
    "#                         st.write(\"**Comment:**\", structured_data['comment'])\n",
    "\n",
    "# def main():\n",
    "#     st.title(\"Educational AI Assistant\")\n",
    "#     st.write(\"\"\"\n",
    "#     Welcome to your interactive learning session! \n",
    "#     Ask any question, and I'll guide you through the concept step by step.\n",
    "#     \"\"\")\n",
    "    \n",
    "#     init_session_state()\n",
    "    \n",
    "#     # Display chat history\n",
    "#     for message in st.session_state.messages:\n",
    "#         display_message(\n",
    "#             message[\"role\"],\n",
    "#             message[\"content\"],\n",
    "#             message.get(\"structured_data\")\n",
    "#         )\n",
    "    \n",
    "#     # Chat input\n",
    "#     if prompt := st.chat_input(\"What would you like to learn about?\"):\n",
    "#         # Display user message\n",
    "#         display_message(\"user\", prompt)\n",
    "#         st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "#         # Get AI response\n",
    "#         response = notebook.get_response(prompt)\n",
    "        \n",
    "#         # Display AI response\n",
    "#         display_message(\n",
    "#             \"assistant\",\n",
    "#             response['ai_message'] if response['ai_message'] else \"\",\n",
    "#             response['structured_response']\n",
    "#         )\n",
    "        \n",
    "#         # Save to session state\n",
    "#         st.session_state.messages.append({\n",
    "#             \"role\": \"assistant\",\n",
    "#             \"content\": response['ai_message'] if response['ai_message'] else \"\",\n",
    "#             \"structured_data\": response['structured_response']\n",
    "#         })\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a84a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !streamlit run /home/shishir/Desktop/Guided-Practice/.venv/lib/python3.12/site-packages/ipykernel_launcher.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Guided Practice)",
   "language": "python",
   "name": "guided-practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
